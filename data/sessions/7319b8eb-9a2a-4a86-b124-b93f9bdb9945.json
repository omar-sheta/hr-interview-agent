{
  "candidate_name": "bob",
  "job_role": "AI Security Engineer",
  "job_description": "You try to make llms protected against ai attacks",
  "questions": [
    "Describe a time you identified and mitigated a vulnerability in a large language model?",
    "Describe a specific prompt injection attack against LLMs that you've investigated, detailing the attack's mechanics, its potential impact, and the mitigation strategies you considered or implemented."
  ],
  "current_question": 2,
  "status": "completed",
  "question_source": "client",
  "used_fallback": false,
  "responses": [
    {
      "question_index": 0,
      "transcript_id": "7319b8eb-9a2a-4a86-b124-b93f9bdb9945_0_1763440528",
      "submitted_at": "2025-11-17T23:35:33.605267"
    },
    {
      "question_index": 1,
      "transcript_id": "7319b8eb-9a2a-4a86-b124-b93f9bdb9945_0_1763440556",
      "submitted_at": "2025-11-17T23:35:58.205212"
    }
  ],
  "session_id": "7319b8eb-9a2a-4a86-b124-b93f9bdb9945",
  "created_at": "2025-11-17T23:35:08.002583",
  "updated_at": "2025-11-17T23:35:58.205988",
  "candidate_id": "1d73b6e7-926e-44e2-a175-6ce2486c80b2",
  "candidate_username": "bob",
  "interview_id": "int-a64f718f-8c38-435b-bd0e-0edacb8adf38",
  "interview_title": "AI Security engineer interview",
  "interview_description": "You secure llm systems",
  "interview_config": {
    "job_role": "AI Security Engineer",
    "job_description": "You try to make llms protected against ai attacks",
    "num_questions": 2,
    "questions": [
      "Describe a time you identified and mitigated a vulnerability in a large language model?",
      "Describe a specific prompt injection attack against LLMs that you've investigated, detailing the attack's mechanics, its potential impact, and the mitigation strategies you considered or implemented."
    ]
  }
}